{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMrHoIV0oNvVtcrHv27S9u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FSValxxC0ggR","executionInfo":{"status":"ok","timestamp":1728543844057,"user_tz":-330,"elapsed":3603,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"efd8c477-7c6f-4176-c9e7-b026a60bc9fd"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["#Tokenisation:\n","#Tokenization is the process of breaking down a piece of text, like a sentence or a paragraph,into individual words or “tokens.”\n","#It is the process of converting a sequence of text into smaller parts, known as tokens.\n","#These tokens can be as small as characters or as long as words.\n","import nltk\n","nltk.download('punkt')\n"]},{"cell_type":"code","source":["# word tokenization using the split() functions\n","my_test = \"\"\"Let's play a game, Would You Rather! It's simple, you have to pick one or the other.\n","Let's get started. Would you rather try Vanilla Ice Cream or Chocolate one? Would you rather be a bird or a bat?\n","Would you rather explore space or the ocean? Would you rather live on Mars or on the Moon?\n","Would you rather have many good friends or one very best friend? Isn't it easy though?\n","When we have less choices, it's easier to decide. But what if the options would be complicated?\n","I guess, you pretty much not understand my point, neither did I, at first place and that led me to a Bad Decision.\"\"\"\n","\n","print(my_test.split())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHNtO3um05s_","executionInfo":{"status":"ok","timestamp":1728369716070,"user_tz":-330,"elapsed":475,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"58c3b3e3-631d-44c3-fd04-ed0afc915b79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"Let's\", 'play', 'a', 'game,', 'Would', 'you', 'Rather!', \"It's\", 'simple,', 'you', 'have', 'to', 'pick', 'one', 'or', 'the', 'other.']\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import(word_tokenize,sent_tokenize,TreebankWordTokenizer,wordpunct_tokenize,TweetTokenizer,MWETokenizer)"],"metadata":{"id":"mPxi0Sby3Oa6","executionInfo":{"status":"ok","timestamp":1728543912760,"user_tz":-330,"elapsed":716,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["txt=\" Work hard stay healthy think positive! #Nitish #Patil\""],"metadata":{"id":"cG3jGHsVPIzY","executionInfo":{"status":"ok","timestamp":1728543915973,"user_tz":-330,"elapsed":429,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Word Tokenizer\n","print(word_tokenize(txt))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8KEJBwJQeAR","executionInfo":{"status":"ok","timestamp":1728544108843,"user_tz":-330,"elapsed":728,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"130d0226-933d-4651-8fd1-e661b80ce284"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['Work', 'hard', 'stay', 'healthy', 'think', 'positive', '!', '#', 'Nitish', '#', 'Patil']\n"]}]},{"cell_type":"code","source":["#Sentence Tokenizer\n","print(sent_tokenize(txt))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qRD-sHfPbmi","executionInfo":{"status":"ok","timestamp":1728543917688,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"d843ece4-f14c-4c1e-bff6-082e4b23dce2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Work hard stay healthy think positive!', '#Nitish #Patil']\n"]}]},{"cell_type":"code","source":["text = 'Hello guys. Welcome to AAFT. You are studying NLP-article'\n","sent_tokenize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oobVzAEwQMYc","executionInfo":{"status":"ok","timestamp":1728544278043,"user_tz":-330,"elapsed":842,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"9449050e-380f-4a61-c68f-612bf9510449"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello guys.', 'Welcome to AAFT.', 'You are studying NLP-article']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["text = 'Hello guys. Welcome to AAFT. You are studying NLP-article'\n","word_tokenize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LN1sRZ8RIAJ","executionInfo":{"status":"ok","timestamp":1728544389971,"user_tz":-330,"elapsed":712,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"def05c3c-a000-4eb0-ccfb-ad6ba69b316c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello',\n"," 'guys',\n"," '.',\n"," 'Welcome',\n"," 'to',\n"," 'AAFT',\n"," '.',\n"," 'You',\n"," 'are',\n"," 'studying',\n"," 'NLP-article']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Punctuation-based tokenizer: This tokenizer splits the sentences into words based on whitespaces and punctuations.\n","print(wordpunct_tokenize(txt))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bv-jorugRjUW","executionInfo":{"status":"ok","timestamp":1728544619542,"user_tz":-330,"elapsed":517,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"89ae21b7-fbad-4b75-82de-1379490f5bd1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['Work', 'hard', 'stay', 'healthy', 'think', 'positive', '!', '#', 'Nitish', '#', 'Patil']\n"]}]},{"cell_type":"code","source":["# Treebank Word tokenizer\n","# This tokenizer incorporates a variety of common rules for english word tokenization. It separates phrase-terminating punctuation like (?!.;,)\n","#from adjacent tokens and retains decimal numbers as a single token. Besides, it contains rules for English contractions.\n","#For example “don’t” is tokenized as [“do”, “n’t”]. You can find all the rules for the Treebank Tokenizer at this link."],"metadata":{"id":"Vy_P4uSMSbdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["txt1= \"What do you don't want to done to yourself, don't do to others...\"\n","tokenizer = TreebankWordTokenizer()\n","print(tokenizer.tokenize(txt1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auQE14wiS3zh","executionInfo":{"status":"ok","timestamp":1728544883053,"user_tz":-330,"elapsed":724,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"4f044968-d2cb-4b5b-ff2e-a8131fa2926e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["['What', 'do', 'you', 'do', \"n't\", 'want', 'to', 'done', 'to', 'yourself', ',', 'do', \"n't\", 'do', 'to', 'others', '...']\n"]}]},{"cell_type":"code","source":["text = \"Hello guys. Welcome to AAFT. You are studying NLP-article\"\n","wordpunct_tokenize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUXt72-rTbvX","executionInfo":{"status":"ok","timestamp":1728544967012,"user_tz":-330,"elapsed":769,"user":{"displayName":"Rishabh Gupta","userId":"09308404502211386282"}},"outputId":"cd3f8c15-dd41-40aa-f55c-34b6babf5c25"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hello',\n"," 'guys',\n"," '.',\n"," 'Welcome',\n"," 'to',\n"," 'AAFT',\n"," '.',\n"," 'You',\n"," 'are',\n"," 'studying',\n"," 'NLP',\n"," '-',\n"," 'article']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"jmshqB3oTwOL"},"execution_count":null,"outputs":[]}]}